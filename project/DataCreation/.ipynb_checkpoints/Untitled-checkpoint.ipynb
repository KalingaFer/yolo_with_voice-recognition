{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c8e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import cv2\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy import signal as sig\n",
    "import scipy.fft as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182e430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_creator_freq_domain(signal, hop_length, window_size, nsamples=160,show=False,pre_filter=sig.tukey): # freq_domain\n",
    "    \n",
    "    # twindow = sig.tukey(frame_length,(2*hop_length)/frame_length)\n",
    "    twindow = pre_filter(np.arange(window_size)) ##frame_length,(2*hop_length)/frame_length)\n",
    "    t_len = len(twindow)\n",
    "    # plt.figure()\n",
    "    # plt.plot(twindow)\n",
    "    # plt.show()\n",
    "    \n",
    "    samples = (signal.shape[0])//hop_length\n",
    "    signal = np.concatenate((signal,np.zeros(window_size)))\n",
    "    # print(samples)\n",
    "    if samples<nsamples:\n",
    "        #print(samples,nsamples)\n",
    "        signal = np.concatenate((signal,np.zeros((nsamples-samples+window_size//hop_length+1)*hop_length) ))\n",
    "        \n",
    "    \n",
    "    sig_2d = np.zeros((nsamples, t_len))\n",
    "    \n",
    "    dct_2d = np.zeros((nsamples, window_size)) \n",
    "    # fft_2d_i = np.zeros((samples, 256))\n",
    "    signal_padded = np.concatenate([signal, np.zeros(t_len)])\n",
    "    # color_image = np.zeros((samples, 128, 3))\n",
    "    for i in range(nsamples):\n",
    "        sig_2d[i, :] = signal_padded[i*hop_length:i*hop_length+t_len]\n",
    "        # z = np.fft.rfft(sig_2d[i, :])\n",
    "        f = np.abs(fft.dct(sig_2d[i, :]*twindow))\n",
    "        f = np.clip(f, 1e-4,100)\n",
    "        z = np.log10(f)\n",
    "        # print(len(z))\n",
    "        # z[0, -1] = 0 + 0j\n",
    "        dct_2d[i, :] = z\n",
    "    \n",
    "    dct_2d[-1,-1] = 2\n",
    "    dct_2d[-1,-2] = -4\n",
    "    \n",
    "    if show:    \n",
    "        plt.figure()\n",
    "        plt.imshow(dct_2d, cmap='yet')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    return dct_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5c5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_dataset_color(dirname,cmap='bwr',nsamples=160,window_size=256,hop_length=128,n_expo=4): # '/mnt/datadrive/datasets/google_speech_commands_dct_v1_kf'\n",
    "    flist = glob.glob('..\\..\\dataset\\google_speech_commands_v0\\*\\*')\n",
    "    filter_func = lambda x: 1 - np.cos(x*np.pi/window_size)**n_expo\n",
    "    # plt.plot(filter_func(np.arange(window_size)))\n",
    "    # plt.show()\n",
    "    # print (len(flist))\n",
    "    dname = f'{dirname}_{cmap}_h{nsamples}_w{window_size*3//4}'\n",
    "\n",
    "    \n",
    "    for index in tqdm(range(0, len(flist)), desc =f\"Audio Dataset: {dname}\"):    \n",
    "        fname = flist[index]\n",
    "        word = fname.split('\\\\')[-2]\n",
    "        new_filename = f'{dname}/{word}/{index}.jpg'\n",
    "        new_dir = f'{dname}/{word}'\n",
    "        os.makedirs(new_dir,exist_ok = True)\n",
    "\n",
    "        signal, sampFreq = librosa.load(fname)\n",
    "\n",
    "        dct_2d = image_creator_freq_domain(signal, hop_length, window_size,pre_filter=filter_func,nsamples=nsamples)\n",
    "        dct_2d = dct_2d[:,:window_size*3//4]\n",
    "        # print (\"image\",dct_2d.shape)\n",
    "        # plt.imshow(dct_2d,cmap=cmap)\n",
    "        # plt.title(new_filename)\n",
    "        # plt.show()\n",
    "        plt.imsave(new_filename,dct_2d,cmap=cmap)\n",
    "    return dname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90542b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Audio Dataset: ../../dataset/audio_dct_gray_h160_w192: 100%|█████████████████████| 64721/64721 [11:57<00:00, 90.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../dataset/audio_dct_gray_h160_w192'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamples = 160\n",
    "create_audio_dataset_color('../../dataset/audio_dct',cmap='bwr',n_expo=4,nsamples=nsamples,window_size=256,hop_length=22500//nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1342537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_directory(dirname,val_split=.15):\n",
    "    \n",
    "    flist = glob.glob(f'{dirname}\\*\\*')\n",
    "    print('flist--',flist)\n",
    "    nfiles = len(flist)\n",
    "    idx = np.random.permutation(np.arange(nfiles))\n",
    "    val_index = int(nfiles*val_split)\n",
    "    val_idx = idx[:val_index]\n",
    "    train_idx = idx[val_index:]\n",
    "    dest_dir = f'{dirname}_split'\n",
    "    \n",
    "    print('val_idx---',val_idx)\n",
    "    \n",
    "    \n",
    "    for c,i in enumerate(val_idx):\n",
    "        fname = flist[i]\n",
    "        word = fname.split('/')[-2]\n",
    "        print('word--',word)\n",
    "        short_fname = fname.split('\\\\')[-1]\n",
    "        new_dname = f'{dest_dir}\\\\val\\\\{word}'\n",
    "        new_fname = f'{dest_dir}\\\\val\\\\{word}/{i}.jpg'\n",
    "        os.makedirs(new_dname,exist_ok = True)\n",
    "        os.symlink(fname,new_fname)\n",
    "        if c%500 == 0:\n",
    "            print (c,\"val\")\n",
    "        \n",
    "    for c,i in enumerate(train_idx):\n",
    "        fname = flist[i]\n",
    "        \n",
    "        word = fname.split('\\\\')[-2]\n",
    "        short_fname = fname.split('\\\\')[-1]\n",
    "        new_dname = f'{dest_dir}\\\\train\\\\{word}'\n",
    "        new_fname = f'{dest_dir}\\\\train\\\\{word}/{i}.jpg'\n",
    "        os.makedirs(new_dname,exist_ok = True)\n",
    "        os.symlink(fname,new_fname)\n",
    "        if c%500 == 0:\n",
    "            print (c,\"train\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24afaae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dirname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124maudio_dct_gray_h160_w192\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# dirname = '/mnt/datadrive/datasets/audio_dct_yr_gray_h120_w144'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msplit_dataset_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m, in \u001b[0;36msplit_dataset_directory\u001b[1;34m(dirname, val_split)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c,i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_idx):\n\u001b[0;32m     14\u001b[0m     fname \u001b[38;5;241m=\u001b[39m flist[i]\n\u001b[1;32m---> 15\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[43mfname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword--\u001b[39m\u001b[38;5;124m'\u001b[39m,word)\n\u001b[0;32m     17\u001b[0m     short_fname \u001b[38;5;241m=\u001b[39m fname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dirname = '..\\\\..\\\\dataset\\\\audio_dct_gray_h160_w192'\n",
    "# dirname = '/mnt/datadrive/datasets/audio_dct_yr_gray_h120_w144'\n",
    "split_dataset_directory(dirname,.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf683d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
